{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x Shape ::  (477, 9)\n",
      "Train_y Shape ::  (477,)\n",
      "Test_x Shape ::  (205, 9)\n",
      "Test_y Shape ::  (205,)\n",
      "[[1, 1, 1, 1, 2, 10, 3, 1, 1]]\n",
      "[2]\n",
      "Actual outcome :: 2 and Predicted outcome :: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supradha/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/supradha/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d4ca4b7b75a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-d4ca4b7b75a7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Actual outcome :: {} and Predicted outcome :: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Accuracy :: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "import pdb\n",
    " \n",
    "# File Paths\n",
    "#OUTPUT_PATH = \"/home/supradha/PycharmProjects/Flaskhello/dataset/breast-cancer-wisconsin.csv\"\n",
    " \n",
    "# Headers\n",
    "HEADERS = [\"CodeNumber\", \"ClumpThickness\", \"UniformityCellSize\", \"UniformityCellShape\", \"MarginalAdhesion\",\n",
    "           \"SingleEpithelialCellSize\", \"BareNuclei\", \"BlandChromatin\", \"NormalNucleoli\", \"Mitoses\", \"CancerType\"]\n",
    " \n",
    " \n",
    "def read_data(path):\n",
    "    \"\"\"\n",
    "    Read the data into pandas dataframe\n",
    "    :param path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"/home/supradha/PycharmProjects/Flaskhello/dataset/breast-cancer-wisconsin.csv\")\n",
    "    return data\n",
    " \n",
    " \n",
    "def get_headers(dataset):\n",
    "    \"\"\"\n",
    "    dataset headers\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return dataset.columns.values\n",
    " \n",
    " \n",
    "def add_headers(dataset, headers):\n",
    "    \"\"\"\n",
    "    Add the headers to the dataset\n",
    "    :param dataset:\n",
    "    :param headers:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset.columns = headers\n",
    "    return dataset\n",
    " \n",
    " \n",
    "def split_dataset(dataset, train_percentage, feature_headers, target_header):\n",
    "    \"\"\"\n",
    "    Split the dataset with train_percentage\n",
    "    :param dataset:\n",
    "    :param train_percentage:\n",
    "    :param feature_headers:\n",
    "    :param target_header:\n",
    "    :return: train_x, test_x, train_y, test_y\n",
    "    \"\"\"\n",
    " \n",
    "    # Split dataset into train and test dataset\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers], dataset[target_header],\n",
    "                                                        train_size=train_percentage)\n",
    "    #print (dataset[feature_headers])\n",
    "    return train_x, test_x, train_y, test_y\n",
    " \n",
    " \n",
    "def handel_missing_values(dataset, missing_values_header, missing_label):\n",
    "    \"\"\"\n",
    "    Filter missing values from the dataset\n",
    "    :param dataset:\n",
    "    :param missing_values_header:\n",
    "    :param missing_label:\n",
    "    :return:\n",
    "    \"\"\"\n",
    " \n",
    "    return dataset[dataset[missing_values_header] != missing_label]\n",
    " \n",
    " \n",
    "def random_forest_classifier(features, target):\n",
    "    \"\"\"\n",
    "    To train the random forest classifier with features and target data\n",
    "    :param features:\n",
    "    :param target:\n",
    "    :return: trained random forest classifier\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(features, target)\n",
    "    return clf\n",
    " \n",
    " \n",
    "def dataset_statistics(dataset):\n",
    "    \"\"\"\n",
    "    Basic statistics of the dataset\n",
    "    :param dataset: Pandas dataframe\n",
    "    :return: None, print the basic statistics of the dataset\n",
    "    \"\"\"\n",
    "    #print (dataset.describe())\n",
    " \n",
    " \n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load the csv file into pandas dataframe\n",
    "    dataset = pd.read_csv(\"/home/supradha/PycharmProjects/Flaskhello/dataset/breast-cancer-wisconsin.csv\")\n",
    "    # Get basic statistics of the loaded dataset\n",
    "    dataset_statistics(dataset)\n",
    " \n",
    "    # Filter missing values\n",
    "    dataset = handel_missing_values(dataset, HEADERS[6], '?')\n",
    "    train_x, test_x, train_y, test_y = split_dataset(dataset, 0.7, HEADERS[1:-1], HEADERS[-1])\n",
    " \n",
    "    # Train and Test dataset size details\n",
    "    print (\"Train_x Shape :: \", train_x.shape)\n",
    "    print (\"Train_y Shape :: \", train_y.shape)\n",
    "    print (\"Test_x Shape :: \", test_x.shape)\n",
    "    print (\"Test_y Shape :: \", test_y.shape)\n",
    " \n",
    "    # Create random forest classifier instance\n",
    "    trained_model = random_forest_classifier(train_x, train_y)\n",
    "    #print (\"Trained model :: \", trained_model)\n",
    "    test_x = [[1,1,1,1,2,10,3,1,1]]\n",
    "    print (test_x)\n",
    "    predictions = trained_model.predict(test_x)\n",
    "    print (predictions)\n",
    " \n",
    "    for i in range(0, 5):\n",
    "        print (\"Actual outcome :: {} and Predicted outcome :: {}\".format(list(test_y)[i], predictions[i]))\n",
    " \n",
    "    print (\"Train Accuracy :: \", accuracy_score(train_y, trained_model.predict(train_x)))\n",
    "    print (\"Test Accuracy  :: \", accuracy_score(test_y, predictions))\n",
    "    print (\" Confusion matrix \", confusion_matrix(test_y, predictions))\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
